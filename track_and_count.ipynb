{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM5moC+XwKhKbWQGYoE7Dld",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Harshal-Kharkar/Amazon/blob/main/track_and_count.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fmd-OCnEYdUL",
        "outputId": "faeffd49-ca27-412c-a576-7abf741d705e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: nvidia-smi: command not found\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "HOME = os.getcwd()\n",
        "print(HOME)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lc6xP_6ZYomb",
        "outputId": "7be9b5e1-0dca-487a-eaa4-74cdc09a70c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd {HOME}\n",
        "!git clone https://github.com/ifzhang/ByteTrack.git\n",
        "%cd {HOME}/ByteTrack\n",
        "\n",
        "# workaround related to https://github.com/roboflow/notebooks/issues/80\n",
        "!sed -i 's/onnx==1.8.1/onnx==1.9.0/g' requirements.txt\n",
        "\n",
        "!pip3 install -q -r requirements.txt\n",
        "!python3 setup.py -q develop\n",
        "!pip install -q cython_bbox\n",
        "!pip install -q onemetric\n",
        "# workaround related to https://github.com/roboflow/notebooks/issues/112 and https://github.com/roboflow/notebooks/issues/106\n",
        "!pip install -q loguru lap thop\n",
        "\n",
        "from IPython import display\n",
        "display.clear_output()\n",
        "\n",
        "\n",
        "import sys\n",
        "sys.path.append(f\"{HOME}/ByteTrack\")\n",
        "\n",
        "\n",
        "import yolox\n",
        "print(\"yolox.__version__:\", yolox.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5O-1pNAGMczL",
        "outputId": "fe15c7ed-3f3b-403b-bceb-1bec62eced5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "yolox.__version__: 0.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from yolox.tracker.byte_tracker import BYTETracker, STrack\n",
        "from onemetric.cv.utils.iou import box_iou_batch\n",
        "from dataclasses import dataclass\n",
        "\n",
        "\n",
        "@dataclass(frozen=True)\n",
        "class BYTETrackerArgs:\n",
        "    track_thresh: float = 0.25\n",
        "    track_buffer: int = 30\n",
        "    match_thresh: float = 0.8\n",
        "    aspect_ratio_thresh: float = 3.0\n",
        "    min_box_area: float = 1.0\n",
        "    mot20: bool = False"
      ],
      "metadata": {
        "id": "GMCf2Do3Q46c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WJh0HC34Q438"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd {HOME}\n",
        "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1pz68D1Gsx80MoPg-_q-IbEdESEmyVLm-' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1pz68D1Gsx80MoPg-_q-IbEdESEmyVLm-\" -O vehicle-counting.mp4 && rm -rf /tmp/cookies.txt\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y6yb9_piY_Fi",
        "outputId": "67185011-07a9-4835-ede8-6d08ff08e922"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "--2025-01-09 09:35:29--  https://docs.google.com/uc?export=download&confirm=&id=1pz68D1Gsx80MoPg-_q-IbEdESEmyVLm-\n",
            "Resolving docs.google.com (docs.google.com)... 142.251.179.138, 142.251.179.102, 142.251.179.113, ...\n",
            "Connecting to docs.google.com (docs.google.com)|142.251.179.138|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://drive.usercontent.google.com/download?id=1pz68D1Gsx80MoPg-_q-IbEdESEmyVLm-&export=download [following]\n",
            "--2025-01-09 09:35:29--  https://drive.usercontent.google.com/download?id=1pz68D1Gsx80MoPg-_q-IbEdESEmyVLm-&export=download\n",
            "Resolving drive.usercontent.google.com (drive.usercontent.google.com)... 142.251.179.132, 2607:f8b0:4004:c1f::84\n",
            "Connecting to drive.usercontent.google.com (drive.usercontent.google.com)|142.251.179.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 35345757 (34M) [video/mp4]\n",
            "Saving to: â€˜vehicle-counting.mp4â€™\n",
            "\n",
            "vehicle-counting.mp 100%[===================>]  33.71M  65.5MB/s    in 0.5s    \n",
            "\n",
            "2025-01-09 09:35:32 (65.5 MB/s) - â€˜vehicle-counting.mp4â€™ saved [35345757/35345757]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SOURCE_VIDEO_PATH = f\"{HOME}/vehicle-counting.mp4\""
      ],
      "metadata": {
        "id": "5mzzWFaMagQ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1sndllQ_agOx",
        "outputId": "a9d090e3-c517-4278-c10f-cb09799e9458"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ultralytics in /usr/local/lib/python3.10/dist-packages (8.3.58)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.26.4)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.10.0.84)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (11.1.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.20.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.2)\n",
            "Requirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.0.13)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.12.14)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display\n",
        "import ultralytics"
      ],
      "metadata": {
        "id": "anuf3NDpagLz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ultralytics.checks()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rxCgNCJ6a5O1",
        "outputId": "1c3ef8f2-409d-400a-d7e6-f94dc4338071"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.58 ðŸš€ Python-3.10.12 torch-2.5.1+cu121 CPU (Intel Xeon 2.20GHz)\n",
            "Setup complete âœ… (2 CPUs, 12.7 GB RAM, 33.4/107.7 GB disk)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install supervision"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "hWuNFU2-a5MT",
        "outputId": "2058564d-aa6d-43ea-c26f-903be96afc52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: supervision in /usr/local/lib/python3.10/dist-packages (0.25.1)\n",
            "Requirement already satisfied: contourpy>=1.0.7 in /usr/local/lib/python3.10/dist-packages (from supervision) (1.3.1)\n",
            "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from supervision) (0.7.1)\n",
            "Requirement already satisfied: matplotlib>=3.6.0 in /usr/local/lib/python3.10/dist-packages (from supervision) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from supervision) (1.26.4)\n",
            "Requirement already satisfied: opencv-python>=4.5.5.64 in /usr/local/lib/python3.10/dist-packages (from supervision) (4.10.0.84)\n",
            "Requirement already satisfied: pillow>=9.4 in /usr/local/lib/python3.10/dist-packages (from supervision) (11.1.0)\n",
            "Requirement already satisfied: pyyaml>=5.3 in /usr/local/lib/python3.10/dist-packages (from supervision) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from supervision) (2.32.3)\n",
            "Requirement already satisfied: scipy<2.0.0,>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from supervision) (1.13.1)\n",
            "Requirement already satisfied: tqdm>=4.62.3 in /usr/local/lib/python3.10/dist-packages (from supervision) (4.67.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6.0->supervision) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6.0->supervision) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6.0->supervision) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6.0->supervision) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6.0->supervision) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6.0->supervision) (2.8.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->supervision) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->supervision) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->supervision) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->supervision) (2024.12.14)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.6.0->supervision) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import supervision as sv"
      ],
      "metadata": {
        "id": "ROKtlMaKbeFU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sv.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5yHK3yo6bjxm",
        "outputId": "18dcab86-c08f-4785-a64b-60abe6f1b0a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.25.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = ultralytics.YOLO('yolov8n.pt')\n",
        "model.fuse()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hBaEM0K2bomT",
        "outputId": "7d916d9c-ba43-4679-a3c4-2706d9af963f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "YOLOv8n summary (fused): 168 layers, 3,151,904 parameters, 0 gradients, 8.7 GFLOPs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd {HOME}\n",
        "!yolo detect predict model=yolov8n.pt conf=0.25 source='https://media.roboflow.com/notebooks/examples/dog.jpeg'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TiOh41xLb83e",
        "outputId": "1d6678dc-0075-4014-d2a5-544422b7e7d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Ultralytics 8.3.58 ðŸš€ Python-3.10.12 torch-2.5.1+cu121 CPU (Intel Xeon 2.20GHz)\n",
            "YOLOv8n summary (fused): 168 layers, 3,151,904 parameters, 0 gradients, 8.7 GFLOPs\n",
            "\n",
            "Found https://media.roboflow.com/notebooks/examples/dog.jpeg locally at dog.jpeg\n",
            "image 1/1 /content/dog.jpeg: 640x384 1 person, 1 car, 1 dog, 334.8ms\n",
            "Speed: 4.7ms preprocess, 334.8ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Results saved to \u001b[1mruns/detect/predict5\u001b[0m\n",
            "ðŸ’¡ Learn more at https://docs.ultralytics.com/modes/predict\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd {HOME}\n",
        "!yolo detect predict model=yolov8n.pt conf=0.25 source='/content/vehicle-counting.mp4'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "p_AVq3N2cg0O",
        "outputId": "1b50e90c-3bef-4d53-9e00-065a1f0bedd0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/yolo\", line 5, in <module>\n",
            "    from ultralytics.cfg import entrypoint\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/__init__.py\", line 11, in <module>\n",
            "    from ultralytics.models import NAS, RTDETR, SAM, YOLO, FastSAM, YOLOWorld\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/models/__init__.py\", line 3, in <module>\n",
            "    from .fastsam import FastSAM\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/models/fastsam/__init__.py\", line 3, in <module>\n",
            "    from .model import FastSAM\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/models/fastsam/model.py\", line 5, in <module>\n",
            "    from ultralytics.engine.model import Model\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/engine/model.py\", line 8, in <module>\n",
            "    import torch\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/__init__.py\", line 2486, in <module>\n",
            "    from torch import _meta_registrations\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_meta_registrations.py\", line 10, in <module>\n",
            "    from torch._decomp import (\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_decomp/__init__.py\", line 249, in <module>\n",
            "    import torch._decomp.decompositions\n",
            "  File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\n",
            "  File \"<frozen importlib._bootstrap>\", line 1006, in _find_and_load_unlocked\n",
            "  File \"<frozen importlib._bootstrap>\", line 688, in _load_unlocked\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 879, in exec_module\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 1012, in get_code\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 672, in _compile_bytecode\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import supervision as sv\n",
        "# # from supervision.video.source import get_video_frames_generator\n",
        "# from tqdm.notebook import tqdm\n",
        "\n",
        "# # Initialize annotators\n",
        "# box_annotator = sv.BoxAnnotator(color=sv.ColorPalette.from_hex(['#ff0000', '#00ff00']), thickness=4)\n",
        "# label_annotator = sv.LabelAnnotator(\n",
        "#     text_color=sv.Color.BLACK,  # Corrected: sv.Color.BLACK\n",
        "#     text_scale=2,  # Adjusted for better visibility\n",
        "#     text_thickness=6,  # Increased text thickness\n",
        "#     text_padding=5,  # Added padding\n",
        "#       # Corrected: Specify the background color\n",
        "# )\n",
        "\n",
        "# # Video source and sink\n",
        "\n",
        "# VIDEO_OUTPUT_PATH = \"output_video.mp4\"  # Path to save the output video\n",
        "\n",
        "# # Generate frames from the source video\n",
        "# gen = sv.get_video_frames_generator(SOURCE_VIDEO_PATH)\n",
        "# gen = iter(gen)\n",
        "\n",
        "# # Get video information\n",
        "# video_info = sv.VideoInfo.from_video_path(SOURCE_VIDEO_PATH)\n",
        "\n",
        "# # Model setup (Ensure you have a model initialized; replace with your actual model code)\n",
        "# # Example: Using YOLO or another object detection model\n",
        "# # model = YourModel()  # Replace with the actual model\n",
        "\n",
        "# with sv.VideoSink(VIDEO_OUTPUT_PATH, video_info) as sink:\n",
        "#     for frame in tqdm(gen, total=video_info.total_frames):  # Iterate through frames\n",
        "#         # Perform inference on the frame (replace with your model's specific prediction code)\n",
        "#         results = model(frame)[0]\n",
        "\n",
        "#         # Extract detections\n",
        "#         detections = sv.Detections(\n",
        "#             xyxy=results.boxes.xyxy.cpu().numpy(),\n",
        "#             confidence=results.boxes.conf.cpu().numpy(),\n",
        "#             class_id=results.boxes.cls.cpu().numpy().astype(int)\n",
        "#         )\n",
        "\n",
        "#         # Step 1: Annotate the frame with bounding boxes\n",
        "#         frame = box_annotator.annotate(scene=frame, detections=detections)\n",
        "\n",
        "#         # Step 2: Annotate the frame with labels\n",
        "#         labels = [\n",
        "#             f\"{model.names[class_id]} {confidence:0.2f}\"\n",
        "#             for confidence, class_id in zip(detections.confidence, detections.class_id)\n",
        "#         ]\n",
        "#         frame = label_annotator.annotate(scene=frame, detections=detections, labels=labels)\n",
        "\n",
        "#         # Write the annotated frame to the video sink\n",
        "#         sink.write_frame(frame)\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "CxYRC5TF5Vrk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# converts Detections into format that can be consumed by match_detections_with_tracks function\n",
        "def detections2boxes(detections: Detections) -> np.ndarray:\n",
        "    return np.hstack((\n",
        "        detections.xyxy,\n",
        "        detections.confidence[:, np.newaxis].astype(np.float64)  # Ensure dtype is correct\n",
        "    ))\n",
        "\n",
        "\n",
        "# converts List[STrack] into format that can be consumed by match_detections_with_tracks function\n",
        "def tracks2boxes(tracks: List[STrack]) -> np.ndarray:\n",
        "    return np.array([\n",
        "        track.tlbr\n",
        "        for track\n",
        "        in tracks\n",
        "    ], dtype=float)\n",
        "\n",
        "\n",
        "# matches our bounding boxes with predictions\n",
        "def match_detections_with_tracks(\n",
        "    detections: Detections,\n",
        "    tracks: List[STrack]\n",
        ") -> Detections:\n",
        "    if not np.any(detections.xyxy) or len(tracks) == 0:\n",
        "        return np.empty((0,))\n",
        "\n",
        "    tracks_boxes = tracks2boxes(tracks=tracks)\n",
        "    iou = box_iou_batch(tracks_boxes, detections.xyxy)\n",
        "    track2detection = np.argmax(iou, axis=1)\n",
        "\n",
        "    tracker_ids = [None] * len(detections)\n",
        "\n",
        "    for tracker_index, detection_index in enumerate(track2detection):\n",
        "        if iou[tracker_index, detection_index] != 0:\n",
        "            tracker_ids[detection_index] = tracks[tracker_index].track_id\n",
        "\n",
        "    return tracker_ids"
      ],
      "metadata": {
        "id": "MtwCRwKoBmYi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# dict maping class_id to class_name\n",
        "CLASS_NAMES_DICT = model.model.names\n",
        "# class_ids of interest - car, motorcycle, bus and truck\n",
        "CLASS_ID = [2, 3, 5, 7]"
      ],
      "metadata": {
        "id": "vibpa19kYzHN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "np.float = float  # Override np.float\n"
      ],
      "metadata": {
        "id": "fNdC4ZondgLq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "k1r-0xw0ikfo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.mps.device_count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X7OECYPIijJQ",
        "outputId": "6776ee4d-f227-45d2-fb3a-5349a3fe65fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(tracker_id_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "drjvrHmex3C7",
        "outputId": "0fbc4eb2-dc70-48a3-82e1-0e39e104a98f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "27"
            ]
          },
          "metadata": {},
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from collections import defaultdict\n",
        "\n",
        "\n",
        "# Create BYTETracker instance\n",
        "byte_tracker = BYTETracker(BYTETrackerArgs())\n",
        "\n",
        "\n",
        "VIDEO_OUTPUT_PATH = \"output_video.mp4\"\n",
        "# Get video info\n",
        "video_info = sv.VideoInfo.from_video_path(SOURCE_VIDEO_PATH)\n",
        "\n",
        "# Create BoxAnnotator\n",
        "box_annotator = sv.BoxAnnotator(color=sv.ColorPalette.from_hex(['#ff0000', '#00ff00']))\n",
        "\n",
        "# Create a LineZone for counting objects that cross a line\n",
        "start, end = sv.Point(x=0, y=1080), sv.Point(x=3840, y=1080)\n",
        "line_zone = sv.LineZone(start=start, end=end)\n",
        "\n",
        "# Default line color (white)\n",
        "line_color = (255, 255, 255)\n",
        "\n",
        "# Counters for In and Out events\n",
        "in_count = 0\n",
        "out_count = 0\n",
        "\n",
        "# Open target video file\n",
        "with sv.VideoSink(VIDEO_OUTPUT_PATH, video_info) as sink:\n",
        "    # Generate frames from the source video\n",
        "    gen = sv.get_video_frames_generator(SOURCE_VIDEO_PATH)\n",
        "    gen = iter(gen)\n",
        "\n",
        "    # Initialize a dictionary to store class counts\n",
        "    class_counts = defaultdict(int)\n",
        "\n",
        "    # Initialize a tracker for sequential IDs\n",
        "    tracker_id_counter = 1\n",
        "    tracker_id_dict = {}\n",
        "\n",
        "    # Loop over video frames\n",
        "    for frame in gen:\n",
        "        # Model prediction on the frame\n",
        "        results = model(frame, verbose=False)\n",
        "        detections = sv.Detections(\n",
        "            xyxy=results[0].boxes.xyxy.cpu().numpy(),\n",
        "            confidence=results[0].boxes.conf.cpu().numpy(),\n",
        "            class_id=results[0].boxes.cls.cpu().numpy().astype(int)\n",
        "        )\n",
        "\n",
        "        # Filtering out detections with unwanted classes (optional)\n",
        "        mask = np.array([class_id in CLASS_ID for class_id in detections.class_id], dtype=bool)\n",
        "        detections.xyxy = detections.xyxy[mask]\n",
        "        detections.confidence = detections.confidence[mask]\n",
        "        detections.class_id = detections.class_id[mask]\n",
        "\n",
        "        if hasattr(detections, 'tracker_id') and detections.tracker_id is not None:\n",
        "            detections.tracker_id = detections.tracker_id[mask]\n",
        "\n",
        "        # Tracking detections using BYTETracker\n",
        "        tracks = byte_tracker.update(\n",
        "            output_results=detections2boxes(detections=detections),\n",
        "            img_info=frame.shape,\n",
        "            img_size=frame.shape\n",
        "        )\n",
        "        tracker_id = match_detections_with_tracks(detections=detections, tracks=tracks)\n",
        "        detections.tracker_id = np.array(tracker_id)\n",
        "\n",
        "        # Assign sequential tracker IDs if needed\n",
        "        for i, tracker_id in enumerate(detections.tracker_id):\n",
        "            if tracker_id not in tracker_id_dict:\n",
        "                tracker_id_dict[tracker_id] = tracker_id_counter\n",
        "                tracker_id_counter += 1  # Increment the counter for the next unique ID\n",
        "            detections.tracker_id[i] = tracker_id_dict[tracker_id]\n",
        "\n",
        "        # Filter out detections without trackers\n",
        "        mask = np.array([tracker_id is not None for tracker_id in detections.tracker_id], dtype=bool)\n",
        "        detections.xyxy = detections.xyxy[mask]\n",
        "        detections.confidence = detections.confidence[mask]\n",
        "        detections.class_id = detections.class_id[mask]\n",
        "        if hasattr(detections, 'tracker_id'):\n",
        "            detections.tracker_id = detections.tracker_id[mask]\n",
        "\n",
        "        # Count the occurrences of each class in the frame\n",
        "        for class_id in detections.class_id:\n",
        "            class_counts[class_id] += 1\n",
        "\n",
        "        # Format custom labels with sequential tracker IDs\n",
        "        labels = [\n",
        "            f\"ID: {tracker_id} {CLASS_NAMES_DICT[class_id]} {confidence:0.2f}\"\n",
        "            for confidence, class_id, tracker_id in zip(detections.confidence, detections.class_id, detections.tracker_id)\n",
        "        ]\n",
        "\n",
        "        # Annotate the frame with bounding boxes and labels\n",
        "        frame = box_annotator.annotate(scene=frame, detections=detections)\n",
        "        frame = label_annotator.annotate(scene=frame, detections=detections, labels=labels)\n",
        "\n",
        "        # Trigger the line crossing event\n",
        "        crossed_in, crossed_out = line_zone.trigger(detections)\n",
        "\n",
        "        # Update counts if objects cross the line\n",
        "        if True in crossed_in:\n",
        "            in_count += 1\n",
        "        if True in crossed_out:\n",
        "            out_count += 1\n",
        "\n",
        "        # Change line color if a crossing event occurs\n",
        "        if True in crossed_in or True in crossed_out:\n",
        "            line_color = (0, 255, 0)  # Change to green\n",
        "        else:\n",
        "            line_color = (255, 255, 255)  # Default to white\n",
        "\n",
        "        # Draw the line on the frame\n",
        "        cv2.line(frame, (start.x, start.y), (end.x, end.y), line_color, thickness=3)\n",
        "\n",
        "        # Display In and Out counts on the frame\n",
        "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "        cv2.putText(frame, f\"In: {in_count}\", (50, 50), font, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
        "        cv2.putText(frame, f\"Out: {out_count}\", (50, 100), font, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
        "\n",
        "        # Write the annotated frame to the output video\n",
        "        sink.write_frame(frame)\n"
      ],
      "metadata": {
        "id": "9fosJvrMzSVR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}